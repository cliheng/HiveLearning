{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hive执行参数"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "命令行直接执行HQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hive -e \"select *from dw.ol_oitf_interface_auc_dimension_business limit 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/hive_e.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "执行HQL文件中的语句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hive -f emp.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/hive_e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hive -f /home/my/hive-script.sql\n",
    "'''\n",
    "Example of running an initialization script before entering interactive mode \n",
    "在进入交互模式之前运行初始化脚本的例子\n",
    "'''\n",
    "HIVE_HOME/bin/hive -i /home/my/hive-init.sql"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "打开调试模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hive --hiveconf hive.root.logger=DEBUG,console "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据导出&导入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从本地文件系统中导入数据到Hive表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load data local inpath 'xiong.txt' into table xiong;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "本地文件系统里面有xiong.txt文件，内容如下：\n",
    "\n",
    "    wangkai8:workSpace$ cat xiong.txt \n",
    "1       xiong     25      13188888888888\n",
    "2       test    30      13888888888888\n",
    "3       zs      34      899314121"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xiong.txt文件中的数据列之间是使用\\t分割的，可以通过下面的语句将这个文件里面的数据导入到xiong表里面，操作如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/loadtxtdata.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "将xiong.txt里面的内容导入到xiong表里面去了，可以到xiong表的数据目录下查看，如下命令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/dfsls.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDFS上导入数据到Hive表"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "从本地文件系统中将数据导入到Hive表的过程中，其实是先将数据临时复制到HDFS的一个目录下（典型的情况是复制到上传用户的HDFS home目录下,比如/home/xiong/），然后再将数据从那个临时目录下移动（注意，这里说的是移动，不是复制！）到对应的Hive表的数据目录里 面。既然如此，那么Hive肯定支持将数据直接从HDFS上的一个目录移动到相应Hive表的数据目录下，假设有下面这个文件/home/xiong /add.txt，具体的操作如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[xiong@master /home/q/hadoop-2.2.0]$ bin/hadoop fs -cat /home/xiong/add.txt\n",
    "5       xiong1    23      131212121212\n",
    "6       xiong2    24      134535353535\n",
    "7       xiong3    25      132453535353\n",
    "8       xiong4    26      154243434355"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "上面是需要插入数据的内容，这个文件是存放在HDFS上/home/xiong目录\n",
    "（和一中提到的不同，一中提到的文件是存放在本地文件系统上）里面，\n",
    "我们可以通过下面的命令将这个文件里面的内容导入到Hive表中，具体操作如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hive> load data inpath '/home/xiong/add.txt' into table xiong;\n",
    "Loading data to table default.xiong\n",
    "Table default.xiong stats:\n",
    "[num_partitions: 0, num_files: 2, num_rows: 0, total_size: 215]\n",
    "OK\n",
    "Time taken: 0.47 seconds\n",
    "\n",
    "hive> select * from xiong;\n",
    "OK\n",
    "      xiong1    23      131212121212\n",
    "      xiong2    24      134535353535\n",
    "      xiong3    25      132453535353\n",
    "      xiong4    26      154243434355\n",
    "      xiong     25      13188888888888\n",
    "      test    30      13888888888888\n",
    "      zs      34      899314121\n",
    "Time taken: 0.096 seconds, Fetched: 7 row(s)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " 从上面的执行结果我们可以看到，数据的确导入到xiong表中了！请注意load data inpath ‘/home/xiong/add.txt’ into table xiong;里面是没有local这个单词的，这个是和一中的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出数据到本地"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hive命令执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "insert overwrite local directory '/home/wangkai8/workSpace/test'\n",
    "row format delimited fields terminated by '\\t' select *from\n",
    "dw.ol_oitf_interface_auc_dimension_business limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果不指定row format delimited fields terminated by '\\t'，字段间默认没有分割符 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/hive_daoshuju.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "命令行直接执行HQL语句导出文件到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " hive -e \"select *from dw.ol_oitf_interface_auc_dimension_business limit 10\" >> emp_export.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出到HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "insert overwrite local directory  'hdfs://hadoopcluster/user/wangkai8/warehouse/xiong' ROW format delimited fields terminated by '\\t'\n",
    " select *from ol_power_line_saler_organization_dim  where dt ='20180808' limit 10;"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "一个源可以同时插入到多个目标表或目标文件，多目标insert可以用一句话来完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FROM src\n",
    "  INSERT OVERWRITE TABLE dest1 SELECT src.* WHERE src.key < 100\n",
    "  INSERT OVERWRITE TABLE dest2 SELECT src.key, src.value WHERE src.key >= 100 and src.key < 200\n",
    "  INSERT OVERWRITE TABLE dest3 PARTITION(ds='2008-04-08', hr='12') SELECT src.key WHERE src.key >= 200 and src.key < 300\n",
    "  INSERT OVERWRITE LOCAL DIRECTORY '/tmp/dest4.out' SELECT src.value WHERE src.key >= 300;\n",
    "Eg:\n",
    "from xi  \n",
    "insert overwrite  table test2 select  '1,2,3' limit 1 \n",
    "insert overwrite  table d select  '4,5,6' limit 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive交互式Shell命令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Command|Description|\n",
    "|-|-|\n",
    "|qui Or exit|退出命令|\n",
    "|！< cmd >|在hive shell中执行shell命令|\n",
    "|dfs < dfs command >|在hive shell中执行dfs命令命令|\n",
    "|add FILE < value > < value > * |将一个文件添加到资源列表中|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eg:\n",
    "      hive> !ls;\n",
    "      hive> dfs -ls;\n",
    "      hive> add FILE /tmp/tt.py;\n",
    "      hive> list FILES;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用python、shell等语言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
